{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d938092c-d878-42cb-8f2c-71e4d14af5f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import current_date, to_date, col, when, lit\n",
    "from datetime import datetime, timedelta\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.window import Window\n",
    "import sys\n",
    "import os\n",
    "from pyspark.sql.utils import AnalysisException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87b8260-057f-4b0b-a5bc-1355261b2b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### DEFINICION DE PIPELINE PARA POSTERIOR CALCULO DE maz_materials_plus; maz_stock_inventory_plus;maz_stock_vw_plus; maz_stock_h_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796f0fdb-3616-41d1-a773-0d343279ea93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "folder_path_ = os.path.dirname(notebook_path)\n",
    "folder_path = f\"/Workspace{folder_path_}\"\n",
    "# folder_path = f\"{folder_path_}\"\n",
    "\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf7bd38-fca1-4f17-b081-3835d5e9b065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.path.abspath(\"../set_project_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3876ece-2e8d-47e4-9b07-5c0e2be386dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def exec_chain_stock_h_plus(mchb,mard,mbew,marc,date):\n",
    "    dbutils.notebook.run(\n",
    "        f\"{folder_path}/test\", \n",
    "        timeout_seconds=0\n",
    "        # arguments={\n",
    "        #     \"mchb\": mchb,\n",
    "        #     \"mard\": mard,\n",
    "        #     \"mbew\": mbew,\n",
    "        #     \"marc\": marc,\n",
    "        # }\n",
    "    )\n",
    "    \n",
    "    maz_materials_plus = dbutils.notebook.run(\n",
    "        f\"{folder_path}/maz_materials_plus\",\n",
    "        timeout_seconds=0,\n",
    "        arguments={\n",
    "            \"mchb\": mchb,\n",
    "            \"mard\": mard\n",
    "        }\n",
    "    )\n",
    "\n",
    "    maz_stock_inventory_plus = dbutils.notebook.run(\n",
    "        f\"{folder_path}/maz_stock_inventory_plus\", \n",
    "        timeout_seconds=0,\n",
    "        arguments={\n",
    "            \"mchb\": mchb,\n",
    "            \"mard\": mard,\n",
    "            \"mbew\": mbew,\n",
    "            \"marc\": marc,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    maz_stock_vw_plus = dbutils.notebook.run(\n",
    "        f\"{folder_path}/maz_stock_vw_plus\", \n",
    "        timeout_seconds=0\n",
    "        # arguments={\n",
    "        #     \"pais\": \"Colombia\",\n",
    "        #     \"anio\": \"2024\"\n",
    "        # }\n",
    "    )\n",
    "\n",
    "    maz_stock_h_plus = dbutils.notebook.run(\n",
    "        f\"{folder_path}/maz_stock_h_plus\", \n",
    "        timeout_seconds=0,\n",
    "        arguments={\n",
    "            \"date_analysis\": date \n",
    "            #.strftime(\"%Y-%m-%d\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        spark.table(\"gld_maz_logistics_warehouse.maz_stock_vw_plus\")\n",
    "        maz_stock_vw_plus=\"SUCCEEDED\"\n",
    "    except:\n",
    "        maz_stock_vw_plus=\"FAILED\"\n",
    "\n",
    "    maz_materials_plus = json.loads(maz_materials_plus)\n",
    "    maz_stock_inventory_plus = json.loads(maz_stock_inventory_plus)\n",
    "    # maz_stock_vw_plus = json.loads(maz_stock_vw_plus)\n",
    "    maz_stock_h_plus = json.loads(maz_stock_h_plus)\n",
    "\n",
    "    row = Row(\n",
    "        fecha_cargada = date,\n",
    "        maz_materials_plus = maz_materials_plus[\"status\"],\n",
    "        maz_stock_inventory_plus = maz_stock_inventory_plus[\"status\"],\n",
    "        maz_stock_vw_plus = maz_stock_vw_plus,\n",
    "        maz_stock_h_plus = maz_stock_h_plus[\"status\"]\n",
    "    )\n",
    "\n",
    "    result_exec = spark.createDataFrame([row]).withColumn(\"exec_status\", when((col(\"maz_materials_plus\") == \"SUCCEEDED\") & (col(\"maz_stock_inventory_plus\") == \"SUCCEEDED\") & (col(\"maz_stock_vw_plus\") == \"SUCCEEDED\") & (col(\"maz_stock_h_plus\") == \"SUCCEEDED\"), \"SUCCEEDED\").otherwise(\"FAILED\"))\n",
    "    return result_exec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4557c470-dd7b-497d-8d78-62b5a745acdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **PIPELINE PARA CALCULO DE maz_copec_marc_lvc; maz_copec_mbew_lvc; maz_copec_mard_lvc; maz_copec_mchb_lvc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a37010b-cb64-41f8-b0c8-4c74a191f465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # ======================================\n",
    "# # CORRER SOLO UNA VEZ, DESPUES COMENTAR\n",
    "# # ======================================\n",
    "\n",
    "# dbutils.notebook.run(\n",
    "#         f\"{folder_path}/maz_copec_marc_lvc\", \n",
    "#         timeout_seconds=0\n",
    "#         # arguments={\n",
    "#         #     \"pais\": \"Colombia\",\n",
    "#         #     \"anio\": \"2024\"\n",
    "#         # }\n",
    "#     )\n",
    "\n",
    "# dbutils.notebook.run(\n",
    "#         f\"{folder_path}/maz_copec_mbew_lvc\", \n",
    "#         timeout_seconds=0\n",
    "#         # arguments={\n",
    "#         #     \"pais\": \"Colombia\",\n",
    "#         #     \"anio\": \"2024\"\n",
    "#         # }\n",
    "#     )\n",
    "\n",
    "# dbutils.notebook.run(\n",
    "#         f\"{folder_path}/maz_copec_mard_lvc\", \n",
    "#         timeout_seconds=0\n",
    "#         # arguments={\n",
    "#         #     \"pais\": \"Colombia\",\n",
    "#         #     \"anio\": \"2024\"\n",
    "#         # }\n",
    "#     )\n",
    "\n",
    "# dbutils.notebook.run(\n",
    "#         f\"{folder_path}/maz_copec_mchb_lvc\", \n",
    "#         timeout_seconds=0\n",
    "#         # arguments={\n",
    "#         #     \"pais\": \"Colombia\",\n",
    "#         #     \"anio\": \"2024\"\n",
    "#         # }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc3c8ed3-ec55-42b4-9862-692ddc7cd592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_subzone = \"copecac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3222069-7f56-4431-bd90-764fcea3760a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "environment = os.getenv(\"ENVIRONMENT\")\n",
    "if environment not in [\"dev\", \"qa\", \"prod\"]:\n",
    "    raise Exception(\n",
    "        \"This Databricks Workspace does not have necessary environment variables.\"\n",
    "        \" Contact the admin team to set up the global init script and restart your cluster.\"\n",
    "    )\n",
    "\n",
    "if environment == 'dev':\n",
    "    uc_name = 'brewdat_uc_maz_dev'\n",
    "elif environment == 'qa':\n",
    "    uc_name = 'brewdat_uc_maz_qa'\n",
    "elif environment == 'prod':\n",
    "    uc_name = 'brewdat_uc_maz_prod'\n",
    "\n",
    "if target_subzone == 'copecac':\n",
    "    mtda_source_schema = 'slv_maz_masterdata_sap_pr3'\n",
    "    supply_source_schema = 'slv_maz_supply_sap_pr3'\n",
    "elif target_subzone == 'mx':\n",
    "    mtda_source_schema = 'slv_maz_masterdata_sap_pr0'\n",
    "    supply_source_schema = 'slv_maz_supply_sap_pr0'\n",
    "\n",
    "print(f\"{mtda_source_schema=}\\n{supply_source_schema=}\\n{uc_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1104872-e26f-49e6-9c8a-a4fae0092dc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b89f21-fe82-4dfc-9d25-c3dbadee875d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **CALCULO MCHB, MARD, MBEW, MARC PARA EL CURRENT DAY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b13623c7-e1ad-42df-aafc-d9ec77e50bb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copecac_mchb_current_date = spark.read.table(f\"brewdat_uc_maz_prod.{supply_source_schema}.{target_subzone}_mchb\").select(\"matnr\", \"werks\", \"lgort\", \"charg\", \"lvorm\", \"clabs\", \"cspem\", \"cinsm\", \"cretm\", \"ceinm\", \"cumlm\", \"cvmum\", \"cvmin\", \"cvmei\", \"cvmsp\", \"cvmre\", \"cvmla\", \"ersda\", \"laeda\", \"op_ind\").filter(F.col(\"op_ind\") != \"D\")\n",
    "\n",
    "copecac_mard_current_date = (\n",
    "        spark.read.table(f\"brewdat_uc_maz_prod.{mtda_source_schema}.{target_subzone}_mard\")\n",
    "        .select(\"matnr\",\"werks\",\"lgort\",\"lvorm\",\"labst\",\"speme\",\"insme\",\"retme\",\"einme\",\"op_ind\")\n",
    "        .filter(~F.col(\"op_ind\").contains(\"D\"))\n",
    "    ) \n",
    "\n",
    "copecac_mbew_current_date = (\n",
    "        spark.read.table(f\"brewdat_uc_maz_prod.{mtda_source_schema}.{target_subzone}_mbew\")\n",
    "        .select(\"matnr\", \"bwkey\", \"salk3\", \"lbkum\", \"vprsv\", \"verpr\", \"stprs\", \"vmpei\", \"peinh\", \"bwtar\", \"op_ind\")\n",
    "        .filter(~F.col(\"op_ind\").contains(\"D\"))\n",
    "        .alias(\"copecac_mbew\")\n",
    "    )\n",
    "\n",
    "copecac_marc_current_date = (\n",
    "    spark.read.table(f\"brewdat_uc_maz_prod.{mtda_source_schema}.{target_subzone}_marc\")\n",
    "    .select(\"matnr\", \"werks\", \"trame\", \"bwesb\", \"umlmc\", \"glgmg\", \"lvorm\", \"op_ind\")\n",
    "    .filter(~F.col(\"op_ind\").contains(\"D\"))\n",
    "    .alias(\"copecac_marc\")\n",
    ")\n",
    "# test=copecac_mchb_current_date\n",
    "# test.createOrReplaceGlobalTempView(\"tabla_test\")\n",
    "copecac_mchb_temp=\"copecac_mchb_temp\"\n",
    "copecac_mard_temp=\"copecac_mard_temp\"\n",
    "copecac_mbew_temp=\"copecac_mbew_temp\"\n",
    "copecac_marc_temp=\"copecac_marc_temp\"\n",
    "copecac_mchb_current_date.createOrReplaceGlobalTempView(copecac_mchb_temp)\n",
    "copecac_mard_current_date.createOrReplaceGlobalTempView(copecac_mard_temp)\n",
    "copecac_mbew_current_date.createOrReplaceGlobalTempView(copecac_mbew_temp)\n",
    "copecac_marc_current_date.createOrReplaceGlobalTempView(copecac_marc_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38730cce-4052-440d-94d9-d3d7e9db517b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **CALCULO maz_stock_h_plus PARA LAS FECHAS QUE SE DEFINAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed0fa184-7e0d-491e-bbeb-f1cf04dc79d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 1. GENERAR LISTA \"dates\" DESDE 2025-10-01 HASTA HOY\n",
    "# =========================================================\n",
    "\n",
    "start_date = datetime.strptime(\"2025-10-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.now()\n",
    "\n",
    "dates = []\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    dates.append(current.strftime(\"%Y-%m-%d\"))\n",
    "    current += timedelta(days=1)\n",
    "\n",
    "print(\"Total dates generated:\", len(dates))\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. CARGAR LA TABLA Y OBTENER insertion_date\n",
    "# =========================================================\n",
    "\n",
    "table_name = f\"brewdat_uc_maz_dev.gld_maz_logistics_warehouse.maz_stock_h_plus\"\n",
    "\n",
    "try:\n",
    "    # Intentar leer la tabla\n",
    "    df_stock = spark.table(table_name)\n",
    "\n",
    "    # Convertir columna\n",
    "    df_stock = df_stock.withColumn(\"insertion_date\", to_date(col(\"insertion_date\")))\n",
    "\n",
    "    # Fechas existentes en la tabla\n",
    "    dates_in_table = [\n",
    "        row[\"insertion_date\"].strftime(\"%Y-%m-%d\")\n",
    "        for row in df_stock.select(\"insertion_date\").distinct().collect()\n",
    "    ]\n",
    "\n",
    "    # Fechas faltantes\n",
    "    missing_dates = [d for d in dates if d not in dates_in_table]\n",
    "\n",
    "    print(\"Tabla encontrada.\")\n",
    "    print(f\"Total fechas faltantes: {len(missing_dates)}\")\n",
    "\n",
    "except AnalysisException:\n",
    "    # La tabla NO existe\n",
    "    print(f\"⚠️ La tabla {table_name} NO existe.\")\n",
    "    print(\"→ Se usarán todas las fechas desde 2025-10-01 hasta hoy.\")\n",
    "\n",
    "    missing_dates = dates\n",
    "    \n",
    "# missing_dates = ['2025-11-24','2025-11-25']\n",
    "\n",
    "\n",
    "print(\"Missing dates:\", missing_dates)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. ITERAR SOBRE MISSING_DATES\n",
    "# =========================================================\n",
    "# Reemplaza estas variables por tus DataFrames reales:\n",
    "# df_mchb, df_mard → para fechas antiguas\n",
    "# copecac_mchb_current_date, copecac_mard_current_date → para la fecha actual\n",
    "\n",
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "row = Row(\n",
    "        fecha_cargada = \"\",\n",
    "        maz_materials_plus = \"\",\n",
    "        maz_stock_inventory_plus = \"\",\n",
    "        maz_stock_vw_plus = \"\",\n",
    "        maz_stock_h_plus = \"\",\n",
    "        exec_status = \"\",\n",
    "        df_mard_count=\"\",\n",
    "        df_mchb_count=\"\",\n",
    "        df_mbew_count=\"\",\n",
    "        df_marc_count=\"\"       \n",
    "    )\n",
    "\n",
    "result_exec_final = spark.createDataFrame([row])\n",
    "\n",
    "for date in missing_dates:\n",
    "\n",
    "    # MARD\n",
    "    w_mard = Window.partitionBy(\n",
    "        \"werks\",\n",
    "        \"matnr\",\n",
    "        \"lgort\"\n",
    "    ).orderBy(\n",
    "        F.col(\"source_commit_ts\").desc(),\n",
    "        F.col(\"__insert_gmt_ts\").desc()\n",
    "    )\n",
    "\n",
    "    df_mard = (\n",
    "        spark.table(\"gld_maz_logistics_warehouse.maz_copec_mard_lvc\")\\\n",
    "        .filter(F.col(\"source_commit_dt\") < date)\\\n",
    "        .withColumn(\"unique_version\", F.row_number().over(w_mard))\\\n",
    "        .filter(F.col(\"unique_version\")==1)\\\n",
    "        .drop(\"unique_version\", \"last_version\")\n",
    "    )\n",
    "    df_mard.cache()\n",
    "    count_mard =df_mard.count()\n",
    "    mard_temp=\"mard_temp\"\n",
    "    df_mard.createOrReplaceGlobalTempView(mard_temp)\n",
    "\n",
    "    # MCHB\n",
    "    w_mchb = Window.partitionBy(\n",
    "        \"werks\",\n",
    "        \"matnr\",\n",
    "        \"lgort\",\n",
    "        \"charg\"\n",
    "    ).orderBy(\n",
    "        F.col(\"source_commit_ts\").desc(),\n",
    "        F.col(\"__insert_gmt_ts\").desc()\n",
    "    )\n",
    "\n",
    "    df_mchb = (\n",
    "        spark.table(\"gld_maz_logistics_warehouse.maz_copec_mchb_lvc\")\\\n",
    "        .filter(F.col(\"source_commit_dt\") < date)\\\n",
    "        .withColumn(\"unique_version\", F.row_number().over(w_mchb))\\\n",
    "        .filter(F.col(\"unique_version\")==1)\\\n",
    "        .drop(\"unique_version\", \"last_version\")\n",
    "    )\n",
    "    df_mchb.cache()\n",
    "    count_mchb =df_mchb.count()\n",
    "    mchb_temp=\"mchb_temp\"\n",
    "    df_mchb.createOrReplaceGlobalTempView(mchb_temp)\n",
    "\n",
    "    # MBEW\n",
    "    w_mbew = Window.partitionBy(\n",
    "        \"matnr\", \n",
    "        \"bwkey\", \n",
    "        \"bwtar\"\n",
    "    ).orderBy(\n",
    "        F.col(\"source_commit_ts\").desc(),\n",
    "        F.col(\"__insert_gmt_ts\").desc()\n",
    "    )\n",
    "\n",
    "    df_mbew = (\n",
    "        spark.table(\"gld_maz_logistics_warehouse.maz_copec_mbew_lvc\")\\\n",
    "        .filter(F.col(\"source_commit_dt\") < date)\\\n",
    "        .withColumn(\"unique_version\", F.row_number().over(w_mbew))\\\n",
    "        .filter(F.col(\"unique_version\")==1)\\\n",
    "        .drop(\"unique_version\", \"last_version\")\n",
    "    )\n",
    "    df_mbew.cache()\n",
    "    count_mbew =df_mbew.count()\n",
    "    mbew_temp=\"mbew_temp\"\n",
    "    df_mbew.createOrReplaceGlobalTempView(mbew_temp)\n",
    "\n",
    "    # MARC\n",
    "    w_marc = Window.partitionBy(\n",
    "        \"matnr\", \n",
    "        \"werks\"\n",
    "    ).orderBy(\n",
    "        F.col(\"source_commit_ts\").desc(),\n",
    "        F.col(\"__insert_gmt_ts\").desc()\n",
    "    )\n",
    "\n",
    "    df_marc = (\n",
    "        spark.table(\"gld_maz_logistics_warehouse.maz_copec_marc_lvc\")\\\n",
    "        .filter(F.col(\"source_commit_dt\") < date)\\\n",
    "        .withColumn(\"unique_version\", F.row_number().over(w_marc))\\\n",
    "        .filter(F.col(\"unique_version\")==1)\\\n",
    "        .drop(\"unique_version\", \"last_version\")\n",
    "    )\n",
    "    df_marc.cache()\n",
    "    count_marc =df_marc.count()\n",
    "    marc_temp=\"marc_temp\"\n",
    "    df_marc.createOrReplaceGlobalTempView(marc_temp)\n",
    "\n",
    "\n",
    "    if date < today_str:\n",
    "        mchb = f\"global_temp.{mchb_temp}\"\n",
    "        mard = f\"global_temp.{mard_temp}\"\n",
    "        mbew = f\"global_temp.{mbew_temp}\"\n",
    "        marc = f\"global_temp.{marc_temp}\"\n",
    "    else:\n",
    "        mchb = f\"global_temp.{copecac_mchb_temp}\"\n",
    "        mard = f\"global_temp.{copecac_mard_temp}\"\n",
    "        mbew = f\"global_temp.{copecac_mbew_temp}\"\n",
    "        marc = f\"global_temp.{copecac_marc_temp}\"\n",
    "\n",
    "    print(f\"Ejecutando para fecha {date}...\")\n",
    "\n",
    "\n",
    "    # Si es una función Python directamente:\n",
    "    final_stock_h_plus=exec_chain_stock_h_plus(mchb, mard, mbew, marc, date)\\\n",
    "                            .withColumn(\"df_mard_count\", lit(count_mard))\\\n",
    "                            .withColumn(\"df_mchb_count\", lit(count_mchb))\\\n",
    "                            .withColumn(\"df_mbew_count\", lit(count_mbew))\\\n",
    "                            .withColumn(\"df_marc_count\", lit(count_marc))\n",
    "    result_exec_final = result_exec_final.unionByName(final_stock_h_plus)\n",
    "    result_exec_final.createOrReplaceGlobalTempView(\"result_exec_final_temp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e5e5a1a-27ba-49ae-b4e7-00bba733549a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# result_exec_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5fadf0-f784-411f-8753-8a3664b6bffe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **BORRADO DE TABLAS maz_materials_plus;maz_stock_inventory_plus;maz_stock_h_plus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c83ff8-ea2f-402c-96e0-a915fe881917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # ===============================================================================\n",
    "# # maz_materials_plus\n",
    "# # ===============================================================================\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_materials_plus').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_materials_plus\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location1='abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_materials_plus'\n",
    "# # target_location1='abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/masterdata/gld_maz_masterdata_materials/maz_materials_plus'\n",
    "# dbutils.fs.rm(target_location1,recurse=True)\n",
    "\n",
    "\n",
    "# # # # # ===============================================================================\n",
    "# # # # # maz_stock_inventory_plus\n",
    "# # # # # ===============================================================================\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_stock_inventory_plus').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_stock_inventory_plus\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location2 = 'abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_stock_inventory_plus'\n",
    "# dbutils.fs.rm(target_location2,recurse=True)\n",
    "\n",
    "\n",
    "# # # # # ===============================================================================\n",
    "# # # # # maz_stock_h_plus\n",
    "# # # # # ===============================================================================\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_stock_h_plus').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_stock_h_plus\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location3 = 'abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_stock_h_plus'\n",
    "# dbutils.fs.rm(target_location3,recurse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "867554cc-ffa7-4340-843c-cca617ae4114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **BORRADO DE TABLAS maz_copec_mard_lvc;maz_copec_mchb_lvc;maz_copec_marc_lvc;maz_copec_mbew_lvc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98834950-4177-4b51-a885-9ca537048d0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # # # ===============================================================================\n",
    "# # # # maz_copec_mard_lvc\n",
    "# # # # ===============================================================================\n",
    "\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_copec_mard_lvc').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_copec_mard_lvc\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location = 'abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_copec_mard_lvc'\n",
    "# dbutils.fs.rm(target_location,recurse=True)\n",
    "\n",
    "# # # # ===============================================================================\n",
    "# # # # maz_copec_mchb_lvc\n",
    "# # # # ===============================================================================\n",
    "\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_copec_mchb_lvc').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_copec_mchb_lvc\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location = 'abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_copec_mchb_lvc'\n",
    "# dbutils.fs.rm(target_location,recurse=True)\n",
    "\n",
    "# # # # ===============================================================================\n",
    "# # # # maz_copec_marc_lvc\n",
    "# # # # ===============================================================================\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_copec_marc_lvc').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_copec_marc_lvc\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location = 'abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_copec_marc_lvc'\n",
    "# dbutils.fs.rm(target_location,recurse=True)\n",
    "\n",
    "# # # # ===============================================================================\n",
    "# # # # maz_copec_mbew_lvc\n",
    "# # # # ===============================================================================\n",
    "\n",
    "# tables = spark.sql(\"SHOW TABLES IN brewdat_uc_maz_dev.gld_maz_logistics_warehouse\")\n",
    "# if tables.filter(tables['tableName'] == 'maz_copec_mbew_lvc').count() > 0:\n",
    "#     sqlquery = \"DROP TABLE gld_maz_logistics_warehouse.maz_copec_mbew_lvc\"\n",
    "#     result = spark.sql(sqlquery)\n",
    "#     display(result)\n",
    "\n",
    "# target_location = 'abfss://gold@brewdatmazslvgldd.dfs.core.windows.net/data/maz/logistics/gld_maz_logistics_warehouse/maz_copec_mbew_lvc'\n",
    "# dbutils.fs.rm(target_location,recurse=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "exec_stock_h_plus",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
